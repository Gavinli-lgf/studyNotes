# 线性代数理论
## Liner Algebra Done Right
1. **向量空间（复数、向量空间的定义、向量空间的性质）**
* 有限维向量空间，线性映射；实数、复数与域field（以后考虑运算性质都是指F域的）；
* 标量包括“复数”（与实数），标量与向量相对；向量、组(tuple)的概念；组的长度是有限的，且长度是一个非负整数（可以为0）；组与集合的区别；F<sup>n</sup>为F域上的高维组（n为正整数，F也包括R、C）；R<sup>1</sup>、R<sup>2</sup>、R<sup>3</sup>的几何模型很明显，分别为线、面、体，R<sup>4</sup>及以上的物理意义就很难想象了；但是对应到C<sup>n</sup>，C<sup>1</sup>是面，但是C<sup>2</sup>及以上的物理意义就很难想象了；F<sup>n</sup>的n较大时，虽然物理意义很难想象，但是“代数”运算法则是不变的（所以叫“线性代数”，而非“线性几何”）；
* 用单个字母来表示含有n个元素的组，而不明确的写出每一个坐标，可以使F<sup>n</sup>上的代数运算表达式更加简洁；（在必须列出坐标时，可以使用该单个字母，加上适当下标的形式来表示；）向量的表示也是相同的逻辑；
* 向量的运算有4个：加法，标量乘法（标量当然包括复数），点积（高维空间的内积），叉积（在高维空间中无推广）；
* 通常说向量空间默认都是F上的（如果只说C、R上的会说明“复向量空间”、“实向量空间”）；
* 向量空间的定义：vector space就是带有加法和标量乘法的集合V，使得交换性、结合性、加法单位元、加法逆、乘法单位元、分配性这6个性质成立（及主要用到2种运算：加法，标量乘法（标量当然包括复数））；
* **1. 向量空间的定义，将向量空间的构成，从“组”拓展到“抽象的对象”，这些抽象的对象包括“函数、其他满足向量空间定义的稀奇古怪的对象”。  2. 因此，向量空间可以是关于多项式的，即多项式的集合。  3. 例如p(F)为系数在F中的所有多项式构成的集合，即所有多项式构成了向量空间。（也就是说只要多项式的系数属于F，那么该多项式都属于这个向量空间）**
* __记住多项式向量空间的加法与标量乘法的表示方式：(P+Q)(z) = P(z)+Q(z) z属于F、(aP)(z) = aP(z) z属于F。那么多项式向量空间的加法单位元是所有系数都为0的多项式。__
  3. 向量空间的性质
* 向量空间有唯一的加法单位元（类似叫法还有“乘法单位元”）；
* 向量空间中的每个元素都有唯一的加法逆；
* 之后定理证明中说的“向量空间”，均指“F”上的向量空间；
* 对每一个v属于V，都有0v=0;(左边0属于F，右边0属于V)
* ...
  4. 子空间（有的叫“线性子空间”）
* U是V的子集，要验证U是否构成一个“子空间”/“线性子空间”，需要验证U满足如下3个性质：加法单位元、对加法封闭、对标量乘法封闭；（向量空间的其他性质在上述性质基础上都是自然成立的）
* 空集是{},而不是{0}；{0}是V的最小子空间，V自身是V的最大子空间；向量空间至少要包含一个元素，即加法单位元；
* 实例：R<sup>2</sup>的子空间有且只有以下3种：{0}、R<sup>2</sup>自身、R<sup>2</sup>中所有过原点的直线；R<sup>3</sup>的子空间有且只有以下4种：{0}、R<sup>3</sup>自身、R<sup>3</sup>中所有过原点的直线、R<sup>3</sup>中所有过原点的平面；
  5. 和与直和（操作对象是：向量空间）
* 和： U<sub>1</sub> ， ... ， U<sub>m</sub>的和U<sub>1</sub> + ... + U<sub>m</sub>，定义为U<sub>1</sub> ， ... ， U<sub>m</sub>中元素所有可能的和所构成的集合。
* 研究向量空间，研究的是“子空间”，而不是任意子集；因为子空间的和，不等于子空间的并集；
* U<sub>1</sub> + ... + U<sub>m</sub>是V中包含U<sub>1</sub> ， ... ， U<sub>m</sub>的最小的子空间。
* 直和：如果V的每个元素都可以“唯一”的写成u<sub>1</sub> + ... + u<sub>m</sub>，其中u<sub>j</sub>属于U<sub>j</sub>，则称V是子空间U<sub>1</sub> ， ... ， U<sub>m</sub>的直和，记为“圈加内部的+号”。（1. 直和符号提醒我们这是特殊类型的子空间和; 2. 不满足唯一性，也不叫直和。）
* 直和对于多项式组成的向量空间也同样成立。
* 1.8 命题：设U<sub>1</sub> ， ... ， U<sub>m</sub>都是V的子空间，则 V = U<sub>1</sub> (+) ... （+） U<sub>m</sub>，当且仅当如下两个条件成立：（1）V = U<sub>1</sub> ， ... ， U<sub>m</sub>；（2）若0 = u<sub>1</sub> + ... + u<sub>m</sub>，u<sub>j</sub>属于U<sub>j</sub>，则每个u<sub>j</sub>都为0。
* “1.8 命题”将“和”、“直和”之间构建了联系；且联系就是0向量表示成时当向量和时表示法的唯一性，即每个分向量都是0。（所以，“和”、“直和”的区别就在“唯一性”上。）
* 1.9 命题：只有2个子空间时，将直和与交集之间建立了联系。
2. **有限维向量空间**
线性代数所关注的只是“有限维向量空间”，有限维向量空间的重要概念有：张成、线性无关、基、维数。
  1. 张成与线性无关：
* （线性）张成（span）:V中一组向量（v<sub>1</sub> , ... , v<sub>m</sub>）的线性组合所构成的集合称为（v<sub>1</sub> , ... , v<sub>m</sub>）的张成。（线性组合的系数都属于F）。
* V中任意一组向量的张成都是V的子空间（为了一致性，声明：空组()的张成等于{0}）。  V中一组向量的张成是包含这组向量的最小子空间。
* 有限维：如果一个向量空间可以由它的一组向量张成，则称该向量空间是有限维的（finite dimensional）。
* 多项式向量空间的表示方法：P<sub>m</sub>(F)，其中m为非负整数，式子表示：系数在F中并且次数不超过m的所有多项式所组成的集合。P<sub>m</sub>(F)是P(F)的子空间。  （不关注无限维向量空间，这是“泛函分析(functional analysis)”所关注的内容；线性代数不关注。）
* 线性无关：V中的一组向量（v<sub>1</sub> , ... , v<sub>m</sub>）的线性组合为0，只有所有系数都为0时才成立，则称该组向量（v<sub>1</sub> , ... , v<sub>m</sub>）是线性无关的。  （从向量无关的组中去除一些向量后，生于的向量组依然即时线性无关的。因此，人为声明空组{}也是线性无关的。）
* 一组向量线性无关，则该组向量的span中的每一个向量，都可以用该组向量的线性组合来唯一的表示。
* 线性相关：不是线性无关，就是线性相关。
* 线性相关性引理：“线性相关”与“线性无关”之间的关系。（具体看书）
* 在有限维向量中，线性无关向量组的长度小于等于张成向量组的长度。
* 有限维向量空间的子空间都是有限维的。
  2. 基
* 若V中的一个向量组既是向量无关的，又张成V，则称之为V的基（basis）。  标准基。
* 一个向量组（v<sub>1</sub> , ... , v<sub>m</sub>）是V的基，当且仅当V中的每一个向量都能用该向量组唯一的表示。
* 在向量空间中，每个张成组都可以化简成一个基。（因为张成组可以是线性相关或线性无关的，如果是线性无关，那其本身就是一个基；如果线性相关，那么总能把其中某个去掉后形成一个基，仍然张成为同一个向量空间。）
* 每个有限维向量空间都有基
* 在有限维向量空间中，每个线性无关向量组都可以拓充成为一个基。
* 设V是有限维的，U是V的一个子空间，则存在V的一个子空间W，是的V是U和W的直和。
  3. 维数
* 有限维向量空间的任意两个基的长度都相同。 任意基的长度称为这个向量空间的维数。
* 特别注意：多项式的维数。 dimP<sub>m</sub>(F) = m + 1 。（即多项式的维数是最高次幂 + 1）
* V是有限维的，并且U是V的子空间，则dimU <= dimV。
* 若V是有限维的，则V中每个长度为dimV的张成向量组都是V的一个基。（也说明了这个长度为dimV的张成向量组是线性无关的）
* 与上同理：若V是有限维的，则V中每个长度为dimV的线性无关向量组都是V的一个基。
* 如果U1 U2都是同一个向量空间的子空间，那么“dim(U1 + U2) = dimU1 + dimU2 - dim(U1交U2)”。
* “直和”与“维数”间的关系：
  设V是有限维的，并且U1，...，U<sub>m</sub>，是V的子空间，使得V = U1 + ... + U<sub>m</sub>，且dimV = dimU1 + ... + dimU<sub>m</sub>，那么V一定是U1，...，U<sub>m</sub>的直和。
3. **线性映射**
向量空间 -> 线性映射（线性变换）
* 线性映射就是一个函数T，实现从“向量空间V -> 向量空间W”的映射，该映射满足以下2个性质：加性(addivity)、齐性(homogeneity)。  （1. 和的线性映射，等于线性影射的和； 2. 标量乘的线性映射，等于线性映射的标量乘。）
* 从向量空间V到向量空间W的所有线性映射所构成的集合记为L(V,W)。
  1. L(V,W)这个映射集合，不仅包括常见的映射矩阵，还包括一些线性操作，比如微分、积分、x<sup>2</sup>乘等。
  2. 确切说，L(V,W)是一个函数集合，函数的定义域向量空间和值域向量空间相同;
  3. 线性映射的向量空间，除了数值向量空间，还包括多项式向量空间。（微分、积分、x<sup>2</sup>乘等，就是针对多项式向量空间的线性映射）
* 常见的线性映射：零映射(zero)、恒等映射(identity)、微分映射(differentiation)、积分映射(integration)、x<sup>2</sup>乘、后向移位(backward shift)、从F<sup>n</sup>到F<sup>m</sup>的映射（该映射关系需要满足一个通用的写法，见书本）
* 线性映射可以根据其在一个基上的取值来构造，而这些基上的取值可以是任意指定的，那么这个映射关系也可以是任意多个的，从而组成一个映射空间。 -> 因为映射关系也是一个向量空间，那么“线性映射”就从“定义域 到 值域”的映射关系，拓展到了“映射关系S 与 映射关系T”这些不同的线性映射关系的向量空间上了。
  1. S,T 属于 L(V,W), 那么 S+T 属于 L(V,W);   a 属于 F，T 属于 L(V,W), 那么aT 属于 L(V,W)。所以证明L(V,W)是一个向量空间。（将线性映射拓展到了映射关系的向量空间上了，该向量空间的加法单位元就是零映射）
  2. 假设S是3*2的映射矩阵，那么S可以实现从“2维到3维”的映射。即一个矩阵是“行数 * 列数”，实现的是“从 列数维空间 到 行数维空间”的映射。
  3. 因此T 属于 L(U,V)，S 属于 L(V,W)，那么ST属于 L(U,W)。即"(ST)(v) = S(Tv)"，ST就是通常的函数复合，如果两个复合函数都是线性的，大多写成“ST”形式，更一般的形式写成S o T。 （注：适当的线性映射的乘积是有用的，但是一般向量空间中两个元素想乘是没有意义的。）
  4. "定义域 到 值域"的映射，“列数维 到 行数维”的映射。所以，可知映射矩阵的“列数”，对应“定义域的维数”；映射矩阵的“行数”，对应“值域的维数”。  （所以采用“L(U,V)”的写法时，可以看作“L(列数，行数)”。）
  5. 对“ST”而言，虽是两个映射的乘积(product)，也是把T当成S的定义域，将T做了S映射。
* 线性映射的乘法满足如下3个性质：结合性(associativity)、恒等映射(identity)、分配性质(distributive properties)。
（线性映射乘法不满足交换率。可以从矩阵乘法方面思考记忆，也可以从多项时方面思考记忆，最重要是一定要拓展到多项式向量空间进行应用。）
* **零空间与值域**
* “零空间”/“核”：令空间是定义域向量空间中，能被映射成0向量的那些向量所组成的子集。（1. 所以零空间是定义域空间的子集; 2. 零空间是相对于映射关系T来说的）
* 零空间示例：微分映射中，nullT为常量函数的集合；x<sup>2</sup>乘的映射中，nullT = {0}；...
* 若“T属于L(V,W)”，则nullT是V的子空间。（由“集合”变为“子空间”，是因为证明了nullT中包含了0，且nullT对标量乘、加法封闭）
* 设“T属于L(V,W)”，则T是单的，当且仅当nullT = {0}。 (即：线性映射T是一对一的充分必要条件是，nullT = {0}。)
* 上述的示例是：线性映射x<sup>2</sup>是单的；但是，线性映射微分映射就不是单的。
* “值域”是W的子空间。（1. 值域定义为Tv的集合，即rangeT; 2. 值域rangeT是W的子空间，而非W的全部。）
* 特例：如果值域rangeT等于W，则说线性映射T：V -> W 是“满的”（surjective/onto）。
* 示例：微分线性映射是满的，但x<sup>2</sup>线性映射就不是满的。（一个线性映射是否为满的，也不是固定的，要看目标空间W的选取。具体见书本）
* （1、“单的”就是说，从定义域空间到值域空间的映射，只有1对1的关系，没有多对1的关系。 2、“满的”就是说W空间种的每个向量都能对应到V空间，即rangeT = W。）
* **如果V是有限维向量空间，并且T属于L(V,W)，那么rangeT是W的有限维子空间，并且dim V = dim nullT + dim rangeT。** （从映射矩阵角度来说，是否可以说一个映射矩阵的“列数 - 行数 = 映射矩阵零空间的维数”？ 答：不可以这么说，因为上面的等式是V与T之间的关系，而不是V、T、W这3者之间的关系。   当线性映射是“单”的时候，rangeT才等于V，才会与V产生实际的关系。）
* 从一个有限维向量空间到比它维数更小的向量空间的线性映射不可能是单的。（书面表达就是：如果V和W都是有限维向量空间，并且dimV > dimW，那么V到W的线性映射一定不是单的。）
* 上述定理的对偶：如果V和W都是有限维向量空间，并且dimV < dimW，那么V到W的线性映射一定不是满的。
* 以上两个推论在线性方程组理论中有一些重要结论：（1）一个齐次方程组中，当变量数多余方程数时，其次线性方程组必有非零解。（2）当方程数多余变量数时，必有一组常数项使得相应的非其次线性方程组无解。（初中时都是用“高斯消元法”来证明，现在用向量空间的理论来证明。）
* **线性映射的矩阵**
* “线性映射的矩阵”所要解决的问题：比如说，在标准3维空间V中有一个向量A,A的坐标是(1,5,3);当把向量空间V做一个扭转，变成了向量空间W，那么原来的向量A在新的向量空间W中的坐标是什么呢？这就是“线性映射的矩阵”这节所要解决的问题。（3Blue1Brown中讲过相应的问题。）
* 实际问题中，只知道2个条件：“定义域向量空间V的基向量”、“定义域向量空间V到目标向量空间W的映射关系T”。而目标向量空间W的基向量是不知道的。那么怎么求V中A在W中的坐标呢？
* 答：就把V中的基向量，都通过T转换成用W的基向量表示的形式（就是书中说的Tv<sub>k</sub>）的系数向量，最终形成对应矩阵M(T)。再根据向量A与V矩阵基向量的线性关系，M(T)体现了V与W基向量之间的线性关系，那么M(T)乘以A就变成了A在W中的坐标。
* 所以将“定义域向量空间V”的基写在M(T)的上方，“目标向量空间W”的基写在M(T)的左侧方。每一列都是V的基向量，映射到W下的向量的坐标。（此时的坐标已经是W下的坐标了，不在是V下的坐标了。）
* 定义域向量空间V的基，总假设是标准基。“标准基”就是第k个基向量的第k个位置是1，其他位置都是0。
* 由以上内容可以推出如下3个结论：（1）映射矩阵M(T,V,W)都是在V使用标准基时求出来的；（2）如果想要求V中向量A在W中的坐标，就使用"M(T)*A"的形式（定义域空间中的向量写在右边，这好像是一个从右向左的处理顺序）；（3）A向量一定要写成列向量的形式（这与几何中常常横着写坐标不同）。
* 定义矩阵之间的3种预算：加法、标量乘法、矩阵乘法。
* “"M(T)*A"的形式（定义域空间中的向量写在右边，这好像是一个从右向左的处理顺序）”这句话的含义也能从下面看出：“线性映射S”：U -> V,“线性映射T”：V -> W,那么总的U -> W的映射关系写成“TS”，而非“ST”。
* “线性映射S”：U -> V,“线性映射T”：V -> W,那么总的U -> W的映射关系写成“TS”。那么M(TS) = M(T)M(S)，该矩阵就是用来将U中的向量A，经过两次映射，在W向量空间下的坐标为“M(TS)*A”。（书中已经证明了“矩阵乘法”的运算就是根据这种映射关系定义的。）
* 两个矩阵A、B乘积成立的前提，不再说“A的列数等于B的行数”，而说“A映射定义域空间的维数，等于B映射值域空间的维数。”
* 两个矩阵A、B，即使AB与BA这两个乘积都成立，那么得出的结果也大概率不相等。（即一个向量V，“先经过A的映射，再经过B的映射”与“先经过B的映射，再经过A的映射”所得到的两个向量，在最终向量空间中的坐标大概率是不同的。）
* 此处将矩阵分为3种：向量v的矩阵，线性变换后向量Tv的矩阵，线性变化关系T的矩阵。M(Tv)=M(T)M(v)。（1、M(v)是列矩阵。 2、好多证明给出的累加，都是向量加法。）
* **可逆性**
* 由胡你矩阵的向量空间解释可得：（1）互逆矩阵S、T，ST、TS结果都是单位矩阵，但是两个单位矩阵的维数却不一定相同。（2）S、T的定义域空间、目标空间一定是相反的（即行数、列数一定是相反的）。（3）如果S的互逆矩阵要么不存在；如果存在，那一定是唯一的。
* 一个线性映射T 为 V->W 是可逆的，当且仅当它既是单的，又是满的。（1、“单的”就是说，从定义域空间到值域空间的映射，只有1对1的关系，没有多对1的关系。 2、“满的”就是说W空间种的每个向量都能对应到V空间，即rangeT = W。）
* “同构的”：如果2个向量空间V、W是可逆的（可逆映射的），也称这两个线性空间是“同构的/同形的”。（即可以认为可逆线性映射就是把向量空间的元素都重新标记了一遍。）
* 两个有限维向量空间同构，当且仅当它们的维数相等。（“可逆矩阵”一定是“方阵”。但“方阵”不一定是可逆的。）
* “Mat(m,n,F)”表示“矩阵集合”。
* 命题：设(v<sub>1</sub>, ... , v<sub>n</sub>)是V的基，设(w<sub>1</sub>, ... , w<sub>m</sub>)是W的基，那么M是L(V,W)和Mat(m,n,F)之间的可逆线性映射。 （这个定理是说：L(V,W)到Mat(m,n,F)的线性映射是可逆的。）
* 只有1个元素为1，其余元素全部为0的m*n矩阵的全体组成了Mat(m,n,F)的基。这样的矩阵共有mn个，因此Mat(m,n,F)的维数等于mn。
* 如果V、W都是一个向量空间，那么V -> W 的映射L(V,W)就是一个新的向量空间。（且L(V,W)的基就如上所述。）
* 如果V、W都是有限维的，那么L(V,W)也是有限维的；且dim L(V,W) = (dim V)(dim W)。
* **“算子”是线性代数中，也是本书中最深刻和最重要的内容。**  算子是一个向量空间到其自身的线性映射。符号表示为L(V)或L(V,V)。
* **设V是有限维的，如果T属于L(V)，那么下列3个条件等价互推：（1）T是可逆的；（2）T是单的；（3）T是满的。** （“算子”跟“多项式”的关系。）
4. **多项式**
* **次数**
* 本章讨论从向量空间到其自身的线性映射时（算子）所需要的关于多项式的一些背景资料。
* “多项式的向量空间”是系数在F中的所有多项式所组成的向量空间，记为P(F)。
* “P<sub>m</sub>(F)”也是一个“多项式向量空间”，是有系数在F中，且次数不超过m的多项式组成的。（因此“P<sub>m</sub>(F)”是P(F)的子集。）
* 命题2（可以表达为）：p是一个m次多项式，如果一个标量lamata是p的根，成立的充分必要条件是“存在(m-1)次多项式q，使得p(z)=(z - lamata)q(z)”,  lamata 属于 F。   （本命题显而易见。）
* 命题3（可以表述为）：一个m次多项式(m >= 0)，最多有m个互不相同的根。
* 推论（可以表述为）：如果一个多项式横等于0，那么它的所有系数一定都等于0。   （即：由多项式的每个次数项为向量，所组成的向量组，在向量空间P(F)中都是线性无关的。  1、所组成的向量组为(1,z, ... ,z<sup>m</sup>)。 2、这个向量组就是子空间p<sub>m</sub>(F)的一个基。）
* “deg p”表示多项式p的次数。
* “带余除法”可以表述为：p、q、r是3个多项式，r是q除以p之后的余项，那么有deg r < deg p 。
* **复系数**
* 代数学基本定理（存在性定理）：每个不是常数的复系数多项式都有根。
* 如果p不是常数的复系数多项式，那么p可以唯一分解(除因子的次序之外)成如下形式p(z)=c(z-y1)...(z-ym),其中c,y1, ... ,ym都是复数。
* **实系数**
* 常用到的实系数概念3个：虚部、实部、复共轭、复数的绝对值；
* 常用到的运算性质9个：实部的可加性、虚部的可加性、共轭的和、共轭的差、共轭的积、复共轭的可加性、复共轭的可乘性、共轭的共轭、绝对值的可乘性。
（“虚数”包含“旋转”的物理含义。从这点出发理解以上9个运算性质，其中需要特别注意的有2个：复共轭的可加性、复共轭的可乘性。）
* 理解：复数的绝对值一定是实数，且值>=0。
* 命题11解释为：对于一个实系数多项式p，其复数根是成对出现的，且每对都是共轭的。（换句话说：如果一个复数y是一个实系数多项式p的根，那么y的共轭也是p的根。）
* 实系数多项式的分解定理：该定理可以从一元二次实系数方程的3个方面考虑：（1）存在实数解的条件(即可以多项式分解的条件)：b<sup>2</sup> >= 4ac。（2）对称轴的值为x=-b/(2a)。（3）y的极值（最大/最小值）。
* 书中讨论实系数多项式的分解定理是，只用“x<sup>2</sup>”项系数为1的形式，而没有用“x<sup>2</sup>”项系数为a的更一般的形式。是因为对任意次幂的实系数多项式"p属于P(R)",p的标准分解形式都是x或“x<sup>2</sup>”项系数为1的形式。能分解的就是x的1次项的标准形式，不能分解的就是x的2次项的标准形式，最外层再乘以系数c。

5. **本征值与本征向量** （？？？下一遍时看一下，从哪一步开始，都说"T-yI"不可逆这个条件？？？）
证明中经常提到"T-yI"“不是单的/不可逆/不是满的”的说法，是因为：如果是单的，那么只有(T-yI)0=0;如果不是单的，那么存在非0向量v使得(T-yI)v=0。
* **不变子空间**
* 向量空间到其自身的线性映射，才构成了线性代数最深刻、最重要的部分。（研究对象：有限维的、非零向量空间。）
* “算子”：从一个向量空间，到其自身的线性映射。
* “不变的（invariant）”：被算子映射到自身的子空间的性质。（即：不变子空间）
* 本征值：对于T属于L(V)和标量y属于F，如果有非零向量u属于V使得“Tu=yu”,则y称为T的本征值。（3Blue1Brown中对应变换前后，仍然保持在标量关系的向量u。）
* 上述描述可叙述为：一个算子有本征值，当且仅当在定义域中存在非零向量，能被该算子映射成此向量的标量倍。
* 相应于不同本征值的非零本征向量，是线性无关的。（由此推论表明：算子的互异本征值的个数，不会多于向量空间的维数。）
* V上的每个算子，最多有dimV个，互不相同的本征值。
* **多项式对算子的作用**
* “算子能自乘为幂”，导致算子的理论要比线性映射的理论丰富。（“幂”：多项式对算子作用的记号和主要概念。）
* 若T属于L(V)，则T<sup>m</sup>有意义，并且也包含于L(V)。（1）当T可逆时，m是任意整数；当T不可逆时，m >= 0。（2）T的幂运算满足正常幂运算的性质。（3）T<sup>0</sup>定义为V上的恒等算子I。
* “多项式乘法的定义”：(pq)(T)=p(T)q(T)=q(T)p(T)。其中p、q的系数都属于F。
* **上三角矩阵**
* 有限维、非零、复向量空间上的每个算子都有本征值。
* 线性代数的一个中心目标：给定一个算子T属于L(V),V有一个基使得T关于此基有比较简单的矩阵（即“有很多0”就叫“简单”。）
* “对角线”：从左上角，到右下角。  “上三角矩阵”：左下方元素全是0。
* “上三角矩阵”与“不变子空间”之间的联系：（1）L(V)中任意一个算子，基于V的基的矩阵，都是“上三角矩阵”。（2）v1能span成v1；v1、v2能span成v2；...;v1、v2、...vk能span成vk(其中k = 1,...n)。（3）v1、v2、...vk能span出来的向量v,经过T的映射,Tv依然属于span(v1、v2、...vk)。
* 定理13：复向量空间V自身映射的每个算子T，都有关于V的某个基具有上三角矩阵。（此结论在“实向量空间”上部成立。）
* 命题：假设V自身映射的某个算子T，有关于V的某个基的上三角矩阵，则当且仅当这个上三角矩阵对角线上的元素都不为0时，矩阵T可逆。
* 命题：假设V自身映射的某个算子T，有关于V的某个基的上三角矩阵，则这个上三角矩阵上的元素，恰好是T的所有本征值。
* **对角矩阵**
* “对角矩阵”都是“上三角矩阵”
* 当且仅当V有一个由T的本征向量组成的基时，算子T关于V的某个基有对角矩阵。
* 同上，算子T由关于V的某个基的对角矩阵，那么该对角线上的元素恰好是该算子的所有本征值。
* 若算子T有dimV个互不相同的本征值，则T关于V的某个基有对角矩阵。（反之不成立）
* 算子关于某个基有对角矩阵的等价条件，共有6个：见p99。（其中(d)、(e)目前还不太理解，要返回去看）
* 互异本征值的非零本征向量线性无关。
* **实向量空间的不变子空间**
* 定理：在有限维、非零、实向量空间中，每个算子都有1维或2维的不变子空间。（即不变子空间不全为1维的）
* （上述表述，以及“复向量空间每个算子都有本征值”的表述，像极了，T的m次多项式的因式分解的形式。）
* 定理：在奇数维实向量空间上，每个算子都有本征值。

6. **内积空间**
研究线性空间，除了线性结构（加法和标量乘）以外的“长度、角度”的概念。引出“内积”。
* **内积**
* “范数”（norm）:||x||。（范数在R<sup>n</sup>上不是线性的）
* “点积”（为了将线性讨论引入范数，而引入的概念）：是R<sup>n</sup>到R的映射。（n维向量到实数的映射。x.y = y.x）
* “内积”（为了将点积推广引入到实向量空间、复向量空间都可用）：<(w1, ... ,wn),(z1, ... ,zn)> = w1z1/ + ... + wnzn/。 （ “欧几里得内积”的概念。）
  1. 正性；
  2. 定性；
  3. 第一个位置的加性；（因为第2个位置会取共轭）
  4. 第一个位置的齐性；（3、4两条可以合并为：对第一个位置的线性要求。）
  5. 共轭对称性；  （<v,w> = <w/,v/>  即取共轭的同时，还要调换位置。）
* 多项式组成的向量空间P<sub>m</sub>(F)上内积的定义：多项式共轭、乘积、(0,1)上积分。
* v、w属于向量空间V，则<v、w>是向量空间V到F（标量）的线性映射。
* 在向量空间中，第2个位置的性质：
  1. 加性。（像第1个位置一样）
  2. 共轭齐性。（与第1个位置不同）
* **范数**
* 向量v的范数 = v的内积的开方。（多项式的范数定义，也是多项式内积的开方）
* 处理范数的平方，通常比直接处理范数容易。
* “正交”（垂直）： ...；
* “正交”分解；
* “柯西-施瓦刺不等式”： ... (把几何向量的点积性质，拓展到“复数向量空间”、“多项式向量空间”)。
* “三角不等式”：两个向量和的范数 <= 单个向量范数之和。（可用于证明两点之间线段最短）
* “平行四边形等式”：在任意平行四边形中，对角线长度的平方和等于四条边长度的平方和。
* **规范正交基**
* “规范正交基”（从内积、范数，引伸而来）：V中的向量组(e1, ... ,em)中任意两个向量<ej, ek>当j != k时，等于0；当j == k时，等于1；那么该向量组就是规范正交的。（将“正交”从2、3维的几何该概念，引入到任意m维的代数概念中。）
* 命题：任意m维的规范正交基上的坐标范数计算公式。（可以从反复使用勾股定理来理解。）
* 推论：V中的向量组(e1, ... ,em)是规范正交的，那么向量组中的这些向量都是线性无关的。（即线性组合等于0时，每个基的系数都等于0。）
* 向量空间V中，任意一个向量组(e1, ... ,em)，只要这个向量组满足如下2个条件，那么其一定是V的规范正交基：（1）向量组是规范正交的；（2）向量组长度为dimV。
* 找到向量空间V中一个点（即一个向量v），在任意基下的坐标很困难，但是找v在规范正交基下的坐标很容易。见如下定理：
* (规范正交基的重要性主要来源于这个定理)  定理：设一个向量组(e1, ... ,en)是V的规范正交基，则对于每个v属于V，都有：（1）v的坐标等于v分别与每个e的点积，即(<v,e1>, ..., <v,en>)；（2）v的范数的平方，等于v分别与每个e的点积的平方的和，即||v||<sup>2</sup> = |<v,e1>|<sup>2</sup> + ... |<v,en>|<sup>2</sup>.
* （既然“规范正交基”这么重要，那么“怎么构造它”呢？） “格拉姆——施密特过程”：只要知道向量空间V中的任意一组线性无关向量组（v1, ... , vm），那么都可以根据这个向量组，使用内积、范数的方法，构造出一组“规范正交基”（e1, ... , em）。构造公式见书籍p118(归纳型的构造公式)
* （“规范正交基”在什么情况下才存在呢？）只要是“有限维内积空间”，都有规范正交基。
* 推论：V中每个规范正交向量组，都可以拓充成V的规范正交基。（也就是说“规范正交基”一定是单的、满的，而规范正交向量组不一定是满的。）
* 推论：向量空间V上的一个算子T，如果T关于V的某个基具有上三角矩阵，那么T关于V的某个规范正交基也具有上三角矩阵。
* 推论：（同上）T是复向量空间V的算子，则T关于V的某个规范正交基具有上三角矩阵。
* **正交投影与极小化问题**
* “正交补”的定义：由向量集合、向量正交，这2个概念引申而来的。（从定义中，可以发现，一个向量u，可以正交于一个向量空间。远超出几何中的理解。  见P121）
* 定理：（正交补、直和、向量空间，3者的关系）如果U是V的子空间，那么“ V = U ‘直和’ ‘U的正交补’ ”。
* U 与 ‘U的正交补’ 这2者的“交集、并集”的运算结果是“{0}、V”。
* 推论：U是V的子空间，那么“U的交补集的交补集”等于U。
* 定义了向量空间V上的新算子P<sub>U</sub>"正交投影"，具有如下5个性质：
  1. P<sub>U</sub>的值域(range)为U；
  2. P<sub>U</sub>的零空间(null)为“U的正交补”；
  3. 任意v都能分解成U与“U的正交补”中两个向量的和"v = u + w"；
  4. ?没看懂？；
  5. v的正交投影的范数 <= v的范数；
* v经过算子P<sub>U</sub>（正交投影）的运算结果，即正交投影在U向量空间中的坐标。易证，见书6.35。
* （关于正交投影的一个“极小化”问题）v - "v在U上的正交投影"，所得向量的范数，小于等于v减u所得向量的范数。其中u是U中的任意向量。（数学公式见P123 6.36）等好成立的条件是：u = P<sub>U</sub>v 。
* “命题6.36 极小化问题”的一个应用：求函数"y = sin x"的逼近。见p124  （该示例将上述极小化问题的应用条件推广到V可以是无限维，只要子空间U是有限维的就行。）
* 现在学到的求逼近的方法有2种：(1) 线性代数求逼近的方法; (2) 泰勒级数求逼近的方法。 这2种方法特点与应用场景不同。

* **线性泛函与伴随**
* 定理：向量空间V上的线性泛函f，存在维一一个向量v，使得v与V中的每个向量u的内积，都等于u的泛函值。即：f(u) = <u,v>, u属于V。
* “伴随”的定义：是根据“映射”、“点积”，这2个概念引伸出来的。当2个矩阵T、T<sup>*</sup>之间满足如下的内积关系时，称T、T<sup>*</sup>互为伴随矩阵。关系式为：<Tv,w> = <v,T<sup>*</sup>w>。
* “伴随矩阵”的一个定义实例。见p129
* 如果T是V -> W的映射，那么T<sup>*</sup>是W -> V的映射。
* T<sup>*</sup>也是线性映射。（满足“加性、齐性”）
* “T -> T<sup>*</sup>”具有如下5个性质：
  1. 加性；
  2. 共轭齐性；
  3. 伴随的伴随；（等于自身）
  4. 恒等算子；（单位矩阵的伴随，等于自身）
  5. 乘积；（乘积的伴随，等于伴随的倒叙乘积）
* 命题：“伴随矩阵、正交补、值域空间(range)、零空间(null)”，这4者之间的相互关系。见p130的命题6.46。
* “共轭转置”与“转置”。
* “矩阵、规范正交基、共轭转置”这3者的关系。见P131 命题6.47。（注意：只有是规范正交基时才成立。）


7. **内积空间上的算子**
* 内积空间上的几类重要算子，都是利用“伴随”的性质详细描述的。
* V是F上的有限维、非零内积空间。




## 零散知识整理
* 梯度向量：
（梯度（英语：gradient）是一种关于多元导数的概括[1]。平常的一元（单变量）函数的导数是标量值函数，而多元函数的梯度是向量值函数。多元可微函数f在点P上的梯度，是以f在P上的偏导数为分量的向量[2]。
  就像一元函数的导数表示这个函数图形的切线的斜率[3]，如果多元函数在点P上的梯度不是零向量，则它的方向是这个函数在P上最大增长的方向、而它的量是在这个方向上的增长率[4]。）

* [浅谈「正定矩阵」和「半正定矩阵」](https://zhuanlan.zhihu.com/p/44860862)
 1. 正定矩阵：给定一个大小为 n*n 的实对称矩阵 A，若对于任意长度为 n 的非零向量 x ，有 x<sup>T</sup>Ax > 0 恒成立，则矩阵 A 是一个正定矩阵。
 2. 半正定矩阵：给定一个大小为 n*n 的实对称矩阵 A，若对于任意长度为 n 的非零向量 x ，有 x<sup>T</sup>Ax >= 0 恒成立，则矩阵 A 是一个半正定矩阵。
 3. 正定矩阵和半正定矩阵的直观解释：若给定任意一个正定矩阵 A 和一个非零向量 x ，则两者相乘得到的向量 y=Ax 与向量 x 的夹角恒小于 90度 . (等价于： x<sup>T</sup>Ax > 0 .)
 4. y = x<sup>T</sup>Ax，就相当于实数的二次函数y = ax<sup>2</sup>的多维表达式。
 5. 推论：
  > 「正定矩阵」和「半正定矩阵」都是对称矩阵；
  > 单位矩阵一定是正定矩阵 (positive definite)。

* 稀疏矩阵/稠密矩阵/稠密度/特殊矩阵：矩阵中非零元素的个数远远小于矩阵元素的总数，并且非零元素的分布没有规律，通常认为矩阵中非零元素的总数比上矩阵所有元素总数的值小于等于0.05时，则称该矩阵为稀疏矩阵(sparse matrix)，该比值称为这个矩阵的稠密度；与之相区别的是，如果非零元素的分布存在规律（如上三角矩阵、下三角矩阵、对角矩阵），则称该矩阵为特殊矩阵。

* ## linear operation
  1. "AB"两个矩阵的“点乘”能成立的前提条件是“A的列数 == B的行数”。（而“A的行数”、“B的列数”这两个因素不用管）

* [矩阵的秩](https://blog.csdn.net/justidle/article/details/110086540)：
  在线性代数中，一个矩阵 A 的列秩是 A 的线性无关的纵列的极大数目。类似地，行秩是 A 的线性无关的横行的极大数目。矩阵的列秩和行秩总是相等的，因此它们可以简单地称作矩阵 A 的秩。通常表示为 r ( A )， r a n k ( A ) 或 r k ( A )。 
  1. m × n 矩阵的秩不大于m且不大于n的一个非负整数，表示为 rk(A) ≤ min(m, n)。有尽可能大的秩的矩阵被称为有满秩；类似的，否则矩阵是秩不足（或称为“欠秩”）的。
  2. 只有零矩阵有秩 0。
  3. 如果方块矩阵 A 是可逆的，当且仅当 A 有秩 n（也就是 A 有满秩）。
  4. 计算矩阵 A 的秩最容易的方法就是高斯消元法，即利用矩阵的初等变换生成一个行阶梯形矩阵，其中数值最小的非零的行数或列数，就是秩。（原因：由于矩阵的初等变化不会改变矩阵的秩。）

# 线性代数工具

## dlqr()
* 离散lqr计算使用的Matrix Difference Riccati Equation，一般迭代几十次就可以收敛；
* Matrix Difference Riccati Equation有2种表示形式，但是不同表示形式的计算量不同（参考老王视频）；

## Eigen的使用
* 矩阵的定义形式有2种：Matrix<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols>、Matrix2d；
  1. Matrix<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols>的形式，只要指明3个参数_Scalar、_Rows、_Cols即可，其他的可不管。
  2. Matrix2d也有多种形式，具体形式如下：
  *\li \c Matrix2d is a 2x2 square matrix of doubles (\c Matrix<double, 2, 2>)
  *\li \c Vector4f is a vector of 4 floats (\c Matrix<float, 4, 1>)
  *\li \c RowVector3i is a row-vector of 3 ints (\c Matrix<int, 1, 3>)
  *
  *\li \c MatrixXf is a dynamic-size matrix of floats (\c Matrix<float, Dynamic, Dynamic>)
  *\li \c VectorXf is a dynamic-size vector of floats (\c Matrix<float, Dynamic, 1>)
  *
  *\li \c Matrix2Xf is a partially fixed-size (dynamic-size) matrix of floats (\c Matrix<float, 2, Dynamic>)
  *\li \c MatrixX3d is a partially dynamic-size (fixed-size) matrix of double (\c Matrix<double, Dynamic, 3>)
注：MatrixXf is a dynamic-size matrix of floats (\c Matrix<float, Dynamic, Dynamic>) //说明“MatrixXf”是一个动态矩阵，但不一定是方阵。
* 矩阵的访问：You can access elements of vectors and matrices using normal subscripting:
  *Eigen::VectorXd v(10);
  *v[0] = 0.1;
  *v[1] = 0.2;
  *v(0) = 0.3;
  *v(1) = 0.4;
  *
  *Eigen::MatrixXi m(10, 10);
  *m(0, 1) = 1;
  *m(0, 2) = 2;
  *m(0, 3) = 3;
* 动态大小矩阵与固定大小矩阵
  Fixed-size means that the numbers of rows and columns are known are compile-time. In this case, Eigen allocates the array of coefficients as a fixed-size array, as a class member. This makes sense for very small matrices, typically up to 4x4, sometimes up to 16x16. Larger matrices should be declared as dynamic-size even if one happens to know their size at compile-time.
* _MaxRows and _MaxCols参数的使用
  In most cases, one just leaves these parameters to the default values.These parameters mean the maximum size of rows and columns that the matrix may have. They are useful in cases when the exact numbers of rows and columns are not known are compile-time, but it is known at compile-time that they cannot exceed a certain value. This happens when taking dynamic-size blocks inside fixed-size matrices: in this case _MaxRows and _MaxCols are the dimensions of the original matrix, while _Rows and _Cols are Dynamic.
* 文件CwiseNullaryOp.h中return type of the Ones(), Zero(), Constant(), Identity() and Random() methods
* block()的使用：block(Index startRow, Index startCol, Index blockRows, Index blockCols)中：
  1. /// \param startRow the first row in the block
  2. /// \param startCol the first column in the block
  3. /// \param blockRows the number of rows in the block
  4. /// \param blockCols the number of columns in the block
* 


